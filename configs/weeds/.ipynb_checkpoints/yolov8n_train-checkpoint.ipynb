{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Weed & Rose Detection with Ultralytics YOLOv8n\n",
    "This notebook trains a YOLOv8 **detection** model (bounding boxes) on the `weeds_yolo` dataset.\n",
    "It follows the same parameters as our YAML config and adds sanity checks, validation, and prediction.\n"
   ],
   "id": "cf850ae4f67baf2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Environment & Versions",
   "id": "5a8da432ae621b9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T12:43:44.640876Z",
     "start_time": "2025-10-23T12:43:38.067720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make sure the notebook kernel is the conda env: Python (yolo)\n",
    "import sys, platform, torch, os\n",
    "import albumentations as A\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"Albumentations version:\", A.__version__)"
   ],
   "id": "4933c4892ca46ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]\n",
      "OS: Windows-10-10.0.26200-SP0\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n",
      "Albumentations version: 2.0.8\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Paths & Config",
   "id": "185d80df7550778c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T12:43:44.781835Z",
     "start_time": "2025-10-23T12:43:44.756839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Paths (edit if you move the project)\n",
    "PROJECT_ROOT = Path(r\"D:/Ai Systems Group\")\n",
    "DATA_YAML    = PROJECT_ROOT / \"data/weeds_yolo/data.yaml\"   # dataset yaml (images/labels)\n",
    "OUT_DIR      = PROJECT_ROOT / \"work_dirs\"                   # where runs will be saved\n",
    "\n",
    "# Training config (directly derived from your YAML)\n",
    "CFG = {\n",
    "    \"data\": str(DATA_YAML),\n",
    "    \"model\": \"yolov8n.pt\",   # detection model\n",
    "    \"epochs\": 100,\n",
    "    \"batch\": 6,              # you chose 4; increase to 8 if VRAM allows\n",
    "    \"imgsz\": 768,\n",
    "    \"workers\": 2,            # keep small on Windows\n",
    "    \"device\": 0,             # GPU id (use 'cpu' to force CPU)\n",
    "    \"project\": str(OUT_DIR),\n",
    "    \"name\": \"yolov8n-weeds\",\n",
    "    \"exist_ok\": False,\n",
    "    \"plots\": True,\n",
    "    \"patience\": 50,\n",
    "    \"seed\": 42,\n",
    "    # \"close_mosaic\": 10,    # optional: refine boxes in last epochs\n",
    "    # \"cache\": \"ram\",       # optional: faster I/O if RAM allows\n",
    "}\n",
    "\n",
    "# Quick sanity checks\n",
    "assert DATA_YAML.exists(), f\"Missing dataset yaml: {DATA_YAML}\"\n",
    "print(\"Config:\", yaml.safe_dump(CFG, sort_keys=False))\n"
   ],
   "id": "42935f6f9d733149",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: data: D:\\Ai Systems Group\\data\\weeds_yolo\\data.yaml\n",
      "model: yolov8n.pt\n",
      "epochs: 100\n",
      "batch: 6\n",
      "imgsz: 768\n",
      "workers: 2\n",
      "device: 0\n",
      "project: D:\\Ai Systems Group\\work_dirs\n",
      "name: yolov8n-weeds\n",
      "exist_ok: false\n",
      "plots: true\n",
      "patience: 50\n",
      "seed: 42\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inspect dataset YAML",
   "id": "f52fe02f146f640b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T12:43:44.875003Z",
     "start_time": "2025-10-23T12:43:44.863007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show dataset YAML contents (class names, paths)\n",
    "with open(DATA_YAML, \"r\", encoding=\"utf-8\") as f:\n",
    "    ds = yaml.safe_load(f)\n",
    "print(ds)\n",
    "\n",
    "# Validate expected structure\n",
    "# path: D:/Ai Systems Group/data/weeds_yolo\n",
    "# train: images/train\n",
    "# val: images/val\n",
    "# names:\n",
    "#   0: Rose\n",
    "#   1: Weed\n"
   ],
   "id": "882897b2c109fa4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'D:/Ai Systems Group/data/weeds_yolo', 'train': 'images/train', 'val': 'images/val', 'names': {0: 'Rose', 1: 'Weed'}}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "3364de9487790427"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-23T12:43:44.906009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(CFG[\"model\"])  # loads yolov8n.pt (detection)\n",
    "results = model.train(\n",
    "    data=CFG[\"data\"],\n",
    "    epochs=CFG[\"epochs\"],\n",
    "    imgsz=CFG[\"imgsz\"],\n",
    "    batch=CFG[\"batch\"],\n",
    "    workers=CFG[\"workers\"],\n",
    "    device=CFG[\"device\"],\n",
    "    project=CFG[\"project\"],\n",
    "    name=CFG[\"name\"],\n",
    "    exist_ok=CFG[\"exist_ok\"],\n",
    "    patience=CFG[\"patience\"],\n",
    "    seed=CFG[\"seed\"],\n",
    "    plots=True,\n",
    "    # close_mosaic=10,      # enable if you uncomment in CFG\n",
    "    # cache=\"ram\",\n",
    "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
    "    degrees=5.0, translate=0.1, scale=0.5, shear=2.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0, fliplr=0.5,\n",
    "    mosaic=0.5,  # try 0.5 if it seems too strong\n",
    "    mixup=0.1,   # small dose\n",
    "    copy_paste=0.0,  # usually off for detection\n",
    "    close_mosaic=10\n",
    ")\n",
    "results\n"
   ],
   "id": "cef0717940a4ea86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.220  Python-3.10.19 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3070 Ti Laptop GPU, 8192MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=6, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Ai Systems Group\\data\\weeds_yolo\\data.yaml, degrees=5.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=yolov8n-weeds2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Ai Systems Group\\work_dirs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Ai Systems Group\\work_dirs\\yolov8n-weeds2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.60.3 ms, read: 768.4127.5 MB/s, size: 6362.3 KB)\n",
      "\u001B[K\u001B[34m\u001B[1mtrain: \u001B[0mScanning D:\\Ai Systems Group\\data\\weeds_yolo\\labels\\train.cache... 63 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 63/63  0.0s\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.70.3 ms, read: 608.789.3 MB/s, size: 7777.0 KB)\n",
      "\u001B[K\u001B[34m\u001B[1mval: \u001B[0mScanning D:\\Ai Systems Group\\data\\weeds_yolo\\labels\\val.cache... 43 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 43/43 9.9Kit/s 0.0s\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# View training curves",
   "id": "71d699cd22e1eb9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:37:23.889241Z",
     "start_time": "2025-10-23T13:37:23.279462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "run_dir = OUT_DIR / \"yolov8n-weeds\"\n",
    "img = run_dir / \"results.png\"\n",
    "if img.exists():\n",
    "    display(Image.open(img))\n",
    "else:\n",
    "    print(\"results.png not found yet:\", img)\n"
   ],
   "id": "b095c4b33e2d42f5",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OUT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m display\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mPIL\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m----> 4\u001B[0m run_dir \u001B[38;5;241m=\u001B[39m \u001B[43mOUT_DIR\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myolov8n-weeds\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      5\u001B[0m img \u001B[38;5;241m=\u001B[39m run_dir \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults.png\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m img\u001B[38;5;241m.\u001B[39mexists():\n",
      "\u001B[1;31mNameError\u001B[0m: name 'OUT_DIR' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Validate on val set (metrics + plots)",
   "id": "8797ed9c4d93c979"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:37:34.898470Z",
     "start_time": "2025-10-23T13:37:34.843060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = model.val(\n",
    "    data=CFG[\"data\"],\n",
    "    project=str(OUT_DIR),\n",
    "    name=f\"{CFG['name']}-val\",\n",
    "    plots=True\n",
    ")\n",
    "metrics\n"
   ],
   "id": "9bafe349284da63d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mval(\n\u001B[0;32m      2\u001B[0m     data\u001B[38;5;241m=\u001B[39mCFG[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m      3\u001B[0m     project\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(OUT_DIR),\n\u001B[0;32m      4\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCFG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-val\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      5\u001B[0m     plots\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m      6\u001B[0m )\n\u001B[0;32m      7\u001B[0m metrics\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predict on some images",
   "id": "383832f9b35b600d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:37:46.942959Z",
     "start_time": "2025-10-23T13:37:46.897086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VAL_IMAGES = Path(ds[\"path\"]) / ds[\"val\"]  # images/val folder\n",
    "pred = model.predict(\n",
    "    source=str(VAL_IMAGES),\n",
    "    project=str(OUT_DIR),\n",
    "    name=f\"{CFG['name']}-pred\",\n",
    "    save=True,      # save images with drawn boxes\n",
    "    save_txt=True,  # save YOLO txt predictions\n",
    "    conf=0.25       # tweak for precision/recall trade-off\n",
    ")\n",
    "pred[:2]\n"
   ],
   "id": "225d204dc45749e2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m VAL_IMAGES \u001B[38;5;241m=\u001B[39m \u001B[43mPath\u001B[49m(ds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m/\u001B[39m ds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m]  \u001B[38;5;66;03m# images/val folder\u001B[39;00m\n\u001B[0;32m      2\u001B[0m pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(\n\u001B[0;32m      3\u001B[0m     source\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(VAL_IMAGES),\n\u001B[0;32m      4\u001B[0m     project\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(OUT_DIR),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      8\u001B[0m     conf\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m       \u001B[38;5;66;03m# tweak for precision/recall trade-off\u001B[39;00m\n\u001B[0;32m      9\u001B[0m )\n\u001B[0;32m     10\u001B[0m pred[:\u001B[38;5;241m2\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Path' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Display a few predictions inline",
   "id": "5e4e498242de2721"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:37:49.927940Z",
     "start_time": "2025-10-23T13:37:49.882024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display\n",
    "pred_dir = OUT_DIR / f\"{CFG['name']}-pred\"\n",
    "imgs = list(pred_dir.glob(\"*.jpg\")) + list(pred_dir.glob(\"*.png\"))\n",
    "print(f\"Showing {min(5, len(imgs))} predictions from:\", pred_dir)\n",
    "for p in imgs[:5]:\n",
    "    display(Image.open(p))\n"
   ],
   "id": "cc884e10214409fb",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OUT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m display\n\u001B[1;32m----> 2\u001B[0m pred_dir \u001B[38;5;241m=\u001B[39m \u001B[43mOUT_DIR\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCFG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-pred\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      3\u001B[0m imgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(pred_dir\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(pred_dir\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*.png\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShowing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mmin\u001B[39m(\u001B[38;5;241m5\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(imgs))\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m predictions from:\u001B[39m\u001B[38;5;124m\"\u001B[39m, pred_dir)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'OUT_DIR' is not defined"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
